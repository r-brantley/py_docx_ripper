{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2614e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules used for extracting information from word / xml documents\n",
    "import os\n",
    "import re\n",
    "import xml.dom.minidom\n",
    "import zipfile\n",
    "from atlassian import confluence\n",
    "\n",
    "# Set root for ripper\n",
    "riproot = \"//\"\n",
    "\n",
    "# is it is a dotfile\n",
    "def dotfile_file(file):\n",
    "    if raw := re.match('^[.][\\S]+$', file) is not None:\n",
    "        return(True)\n",
    "\n",
    "# is it docx file extension?\n",
    "def docx_file(file):\n",
    "    if raw := re.search('^[^.]+$|\\.(?=docx)[^. \\n\\r]', file) is not None:\n",
    "        return(True)\n",
    "\n",
    "# function to get the path to the file to define breadcrumb taxonomy\n",
    "def doc_tax(path):\n",
    "    slices = []\n",
    "    cookie = path.split(\"/\")\n",
    "    if (len(cookie) >= 1 and range(len(cookie))):\n",
    "        for c in range(len(cookie)):\n",
    "            slices.append(cookie[c])\n",
    "    return(slices)\n",
    "\n",
    "# pipe the XML content section of docx to string\n",
    "def str_xml(file):\n",
    "    docx = zipfile.ZipFile(file, mode=\"r\")\n",
    "    ripxml = xml.dom.minidom.parseString(docx.read('word/document.xml'))\n",
    "    ripxml = str(docx.read('word/document.xml'))\n",
    "    docx.close\n",
    "    return ripxml\n",
    "    \n",
    "# pull the relevant groups and sections out of the docx XML\n",
    "def nsx(doc):\n",
    "        out = []\n",
    "        scan = re.findall(r'(<w[^>]+(?:/>|>)(?:.*?)</w:t>)',doc)\n",
    "        style_scan = re.compile(r'<w:pStyle w:val=\\\"([\\S]+)\\\"')\n",
    "        content_scan = re.compile(r'(?:<w:t(?: xml.*?\\\">|>))(.*?)</w:t>')\n",
    "\n",
    "        for w in range(len(scan)):\n",
    "            if style_scan.findall(scan[w]):    \n",
    "                dx_style = style_scan.findall(scan[w])[0]\n",
    "            else:\n",
    "                dx_style = \"default\"\n",
    "\n",
    "            if content_scan.findall(scan[w]):\n",
    "                content = content_scan.findall(scan[w])[0]\n",
    "                cdict = {\n",
    "                    \"style\": dx_style,\n",
    "                    \"body\": content\n",
    "                }\n",
    "                out.append(cdict)\n",
    "                \n",
    "        return out\n",
    "\n",
    "def tree_printer(riproot):\n",
    "    payload = []\n",
    "\n",
    "    for root, dirs, files in os.walk(riproot): #walk the dir specified for docs\n",
    "        for f in range(len(files)):\n",
    "            file = files[f]\n",
    "\n",
    "            if not dotfile_file(file): #skip dotfiles\n",
    "                taxroot = root.split(riproot)[1] #capture taxonomy root of SOP\n",
    "                \n",
    "                if docx_file(file):\n",
    "                    content = str_xml(root+\"/\"+file)\n",
    "                    content = nsx(content)\n",
    "                    rip_out = {\n",
    "                        'file': file,\n",
    "                        'root': root,\n",
    "                        'taxonomy': taxroot,\n",
    "                        'content': content\n",
    "                    }\n",
    "                    payload.append(rip_out)\n",
    "                \n",
    "                if not docx_file(file): #handle non-docx files that are not dotfiles\n",
    "                    pass\n",
    "\n",
    "    return payload\n",
    "\n",
    "#def uq(alist):\n",
    "#    out = []\n",
    "#    alist = (list(alist))\n",
    "#    for x in range(len(alist)):\n",
    "#       for y in range(len(alist[x][\"content\"])):\n",
    "#           print(alist[x][\"content\"][y])\n",
    "#           if alist[x][\"content\"][y][\"style\"] not in out:\n",
    "#               out.append(str(alist[x][\"content\"][y][\"style\"]))\n",
    "#    return out\n",
    "#allofit = tree_printer(riproot)\n",
    "#print(*uq(allofit), sep=\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "style_xmap = {\n",
    "    \"AppendixSubHeading\":\"$\",\n",
    "    \"Body\":\"$\",\n",
    "    \"BodyText\":\"$\",\n",
    "    \"BodyTextFirstIndent\":\"$\",\n",
    "    \"BodyTextIndent\":\"$\",\n",
    "    \"Bullet1\":\"* $\",\n",
    "    \"DocumentHeader\":\"h1. $\",\n",
    "    \"Header\":\"$\",\n",
    "    \"Heading1\":\"h1. $\",\n",
    "    \"Heading2\":\"h2. $\",\n",
    "    \"Heading3\":\"h3. $\",\n",
    "    \"Heading4\":\"h4. $\",\n",
    "    \"HTMLPreformatted\":\"$\",\n",
    "    \"Index1\":\"$\",\n",
    "    \"Index2\":\"$\",\n",
    "    \"ListBullet2\":\"* $\",\n",
    "    \"Listnumbers\":\"# $\",\n",
    "    \"ListParagraph\":\"* $\",\n",
    "    \"NestedList\":\"* $\",\n",
    "    \"NestedList4\":\"* $\",\n",
    "    \"NestedList5\":\"* $\",\n",
    "    \"NormalWeb\":\"$\",\n",
    "    \"Number-OMN\":\"$\",\n",
    "    \"PlainText\":\"$\",\n",
    "    \"r4\":\"$\",\n",
    "    \"SOPBody\":\"$\",\n",
    "    \"SOPBodyBullet\":\"* $\",\n",
    "    \"SOPHeaderTable\":\"||heading $| \",\n",
    "    \"Subtitle\":\"$\",\n",
    "    \"TableHeading\":\"||heading $|\",\n",
    "    \"TOC1\":\"# $\",\n",
    "    \"TOC2\":\"## $\",\n",
    "    \"TOC3\":\"### $\",\n",
    "    \"TOCHeading\":\"h2. $\",\n",
    "    \"Warning\":\"{{color:red}}${{color}}\"\n",
    "}\n",
    "\n",
    "allofit = tree_printer(riproot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_docx_ripper-jq3e5XPX",
   "language": "python",
   "name": "py_docx_ripper-jq3e5xpx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
